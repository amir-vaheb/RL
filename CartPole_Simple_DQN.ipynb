{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPole_Simple_DQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elk-cloner/RL/blob/master/CartPole_Simple_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEQK0GLD58BM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "9fea3551-5e14-4ed6-f99b-dfe326c7b737"
      },
      "source": [
        "# using https://colab.research.google.com/drive/1flu31ulJlgiRL1dnN2ir8wGh9p7Zij2t guide to\n",
        "# show openai gym env in jupyter\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip uninstall pyglet\n",
        "!pip install pyglet==1.3.2\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1\n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling pyglet-1.3.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/pyglet-1.3.2.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/pyglet/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled pyglet-1.3.2\n",
            "Collecting pyglet==1.3.2\n",
            "  Using cached https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.2) (0.16.0)\n",
            "Installing collected packages: pyglet\n",
            "Successfully installed pyglet-1.3.2\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (41.4.0)\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 70kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0 (from tensorflow-gpu)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow-gpu)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (41.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0rc3 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0rc3 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-estimator-2.0.0 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8g8Ar8eGiwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import gym\n",
        "import math\n",
        "import glob\n",
        "import base64\n",
        "import random\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import count\n",
        "from collections import deque\n",
        "from IPython.display import HTML\n",
        "from gym.wrappers import Monitor\n",
        "from gym import logger as gymlogger\n",
        "gymlogger.set_level(40) #error only\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5hzhSVr5FpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d0a79231-b6e5-4055-a669-78df3f7e5dff"
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env\n",
        "\n",
        "# env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
        "# show_video()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izo3yfjl5Nu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define fome global variables\n",
        "MEMORY_BUFFER = deque(maxlen=10000)\n",
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.999\n",
        "ORACLE_UPDATE_INTERVAL = 10\n",
        "ACTION_SPACE = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0btxx685N6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define very simple DQN network\n",
        "def DQNModel():\n",
        "    policy_model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(input_shape=(4,), units=16, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(units=16, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(units=2, activation=\"linear\")\n",
        "    ])\n",
        "    return policy_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q_a8jkdAOGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d2814856-a0c2-4389-d5c1-fe33bbeafb0d"
      },
      "source": [
        "# define Q-network and Q*-network(oracle)\n",
        "dqn_net = DQNModel()\n",
        "oracle_net = tf.keras.models.clone_model(dqn_net)\n",
        "\n",
        "# define loss function and optimizer\n",
        "loss_func = tf.keras.losses.MeanSquaredError()\n",
        "optimizer = optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=1)\n",
        "\n",
        "print(dqn_net.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 16)                80        \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 386\n",
            "Trainable params: 386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPJMIPpK81QW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using vanila epsilon greedy to choose action\n",
        "def select_action(current_state):\n",
        "    if np.random.rand() < 0.5:\n",
        "        return random.sample(ACTION_SPACE,1)[0]\n",
        "    current_state = np.array(current_state).reshape(1, -1)\n",
        "    action_score = dqn_net.predict(current_state)\n",
        "    return tf.math.argmax(action_score, axis=1).numpy()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmCT1n_99yfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(MEMORY_BUFFER) < BATCH_SIZE:\n",
        "        return 0\n",
        "\n",
        "    sample_batch = random.sample(MEMORY_BUFFER, BATCH_SIZE)\n",
        "    y = np.zeros(shape=[1, len(sample_batch)])\n",
        "\n",
        "    for i, sample in enumerate(sample_batch):\n",
        "        current_state, action, next_state, reward, done = sample\n",
        "        if done:\n",
        "            y[0][i] = reward\n",
        "        else:\n",
        "            next_state = np.array(next_state).reshape(1, -1)\n",
        "            target_model_score = tf.math.reduce_max(oracle_net.predict(next_state)).numpy()\n",
        "            y[0][i] = GAMMA * target_model_score + reward\n",
        "\n",
        "    batch_current_state = []\n",
        "    batch_action = np.zeros(shape=[BATCH_SIZE, 2], dtype=np.int32)\n",
        "    for i, sample in enumerate(sample_batch):\n",
        "        current_state, action, next_state, reward, _ = sample\n",
        "        batch_current_state.append(current_state)\n",
        "        batch_action[i][0] = i\n",
        "        batch_action[i][1] = action\n",
        "\n",
        "    batch_current_state = np.array(batch_current_state)\n",
        "\n",
        "    with tf.GradientTape() as gradient_tape:\n",
        "        x = dqn_net(batch_current_state)\n",
        "        x = tf.gather_nd(x, batch_action)\n",
        "        loss = loss_func(y, x)\n",
        "        gradient = gradient_tape.gradient(loss, dqn_net.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradient, dqn_net.trainable_variables))\n",
        "\n",
        "    return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EStnIayn_Xto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def solved():\n",
        "    # Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\n",
        "    oracle_net.load_weights(\"./pre_train_model/\")\n",
        "    env = gym.make(\"CartPole-v0\")\n",
        "    trials_rewards = []\n",
        "    for i in range(100):\n",
        "        current_state = env.reset()\n",
        "        total_rewards = 0\n",
        "        while True:\n",
        "            current_state = np.array(current_state).reshape(1, -1)\n",
        "            action_score = oracle_net.predict(current_state)\n",
        "            action = tf.math.argmax(action_score, axis=1).numpy()[0]\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            current_state = next_state\n",
        "            if done:\n",
        "                break\n",
        "            total_rewards += reward\n",
        "        trials_rewards.append(total_rewards)\n",
        "    mean_rewards = sum(trials_rewards) / len(trials_rewards)\n",
        "    print(f\"mean rewards for 100 consecutive trials: {mean_rewards}\") \n",
        "    if mean_rewards >= 195.0:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM4BGXHCME6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def render_model():\n",
        "    oracle_net.load_weights(\"./pre_train_model/\")\n",
        "    env = wrap_env(gym.make(\"CartPole-v0\"))\n",
        "    current_state = env.reset()\n",
        "    while True:\n",
        "        env.render()\n",
        "        current_state = np.array(current_state).reshape(1, -1)\n",
        "        action_score = oracle_net.predict(current_state)\n",
        "        action = tf.math.argmax(action_score, axis=1).numpy()[0]\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        current_state = next_state\n",
        "        if done:\n",
        "            break\n",
        "    env.close()\n",
        "    show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-LNDzOZAwaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40769b21-b579-4e57-c541-425c2e55e099"
      },
      "source": [
        "score_epoch = []\n",
        "optimize_steps = 0\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "ACTION_SPACE = list(range(env.action_space.n))\n",
        "\n",
        "for trial_number in count():\n",
        "    current_state = env.reset()\n",
        "    print(f\"trial number: {trial_number}\")\n",
        "    while True:\n",
        "        action_num = select_action(current_state)\n",
        "        next_state, reward, done, info = env.step(action_num)\n",
        "        reward = reward if not done else -1 * reward\n",
        "        MEMORY_BUFFER.append(tuple([current_state, action_num, next_state, reward, done]))\n",
        "        optimize_steps += optimize_model()\n",
        "        current_state = next_state\n",
        "        if optimize_steps and optimize_steps % ORACLE_UPDATE_INTERVAL == 0:\n",
        "            oracle_net.set_weights(dqn_net.get_weights())\n",
        "            oracle_net.save_weights(\"./pre_train_model/\")\n",
        "        if done:\n",
        "            break\n",
        "    if optimize_steps > 0 and solved():\n",
        "        print(f\"solved after {trial_number} episods\")\n",
        "        break"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trial number: 0\n",
            "mean rewards for 100 consecutive trials: 8.39\n",
            "trial number: 1\n",
            "mean rewards for 100 consecutive trials: 8.27\n",
            "trial number: 2\n",
            "mean rewards for 100 consecutive trials: 8.48\n",
            "trial number: 3\n",
            "mean rewards for 100 consecutive trials: 8.31\n",
            "trial number: 4\n",
            "mean rewards for 100 consecutive trials: 8.4\n",
            "trial number: 5\n",
            "mean rewards for 100 consecutive trials: 8.5\n",
            "trial number: 6\n",
            "mean rewards for 100 consecutive trials: 8.27\n",
            "trial number: 7\n",
            "mean rewards for 100 consecutive trials: 8.43\n",
            "trial number: 8\n",
            "mean rewards for 100 consecutive trials: 8.35\n",
            "trial number: 9\n",
            "mean rewards for 100 consecutive trials: 8.41\n",
            "trial number: 10\n",
            "mean rewards for 100 consecutive trials: 8.29\n",
            "trial number: 11\n",
            "mean rewards for 100 consecutive trials: 8.44\n",
            "trial number: 12\n",
            "mean rewards for 100 consecutive trials: 8.32\n",
            "trial number: 13\n",
            "mean rewards for 100 consecutive trials: 8.31\n",
            "trial number: 14\n",
            "mean rewards for 100 consecutive trials: 8.32\n",
            "trial number: 15\n",
            "mean rewards for 100 consecutive trials: 8.37\n",
            "trial number: 16\n",
            "mean rewards for 100 consecutive trials: 8.34\n",
            "trial number: 17\n",
            "mean rewards for 100 consecutive trials: 8.34\n",
            "trial number: 18\n",
            "mean rewards for 100 consecutive trials: 8.36\n",
            "trial number: 19\n",
            "mean rewards for 100 consecutive trials: 8.45\n",
            "trial number: 20\n",
            "mean rewards for 100 consecutive trials: 8.49\n",
            "trial number: 21\n",
            "mean rewards for 100 consecutive trials: 8.49\n",
            "trial number: 22\n",
            "mean rewards for 100 consecutive trials: 8.31\n",
            "trial number: 23\n",
            "mean rewards for 100 consecutive trials: 8.39\n",
            "trial number: 24\n",
            "mean rewards for 100 consecutive trials: 8.34\n",
            "trial number: 25\n",
            "mean rewards for 100 consecutive trials: 8.45\n",
            "trial number: 26\n",
            "mean rewards for 100 consecutive trials: 8.31\n",
            "trial number: 27\n",
            "mean rewards for 100 consecutive trials: 8.4\n",
            "trial number: 28\n",
            "mean rewards for 100 consecutive trials: 8.38\n",
            "trial number: 29\n",
            "mean rewards for 100 consecutive trials: 8.36\n",
            "trial number: 30\n",
            "mean rewards for 100 consecutive trials: 8.35\n",
            "trial number: 31\n",
            "mean rewards for 100 consecutive trials: 8.36\n",
            "trial number: 32\n",
            "mean rewards for 100 consecutive trials: 8.39\n",
            "trial number: 33\n",
            "mean rewards for 100 consecutive trials: 8.47\n",
            "trial number: 34\n",
            "mean rewards for 100 consecutive trials: 8.28\n",
            "trial number: 35\n",
            "mean rewards for 100 consecutive trials: 8.31\n",
            "trial number: 36\n",
            "mean rewards for 100 consecutive trials: 8.2\n",
            "trial number: 37\n",
            "mean rewards for 100 consecutive trials: 8.32\n",
            "trial number: 38\n",
            "mean rewards for 100 consecutive trials: 9.58\n",
            "trial number: 39\n",
            "mean rewards for 100 consecutive trials: 9.38\n",
            "trial number: 40\n",
            "mean rewards for 100 consecutive trials: 10.15\n",
            "trial number: 41\n",
            "mean rewards for 100 consecutive trials: 11.26\n",
            "trial number: 42\n",
            "mean rewards for 100 consecutive trials: 156.85\n",
            "trial number: 43\n",
            "mean rewards for 100 consecutive trials: 122.79\n",
            "trial number: 44\n",
            "mean rewards for 100 consecutive trials: 52.68\n",
            "trial number: 45\n",
            "mean rewards for 100 consecutive trials: 47.45\n",
            "trial number: 46\n",
            "mean rewards for 100 consecutive trials: 39.4\n",
            "trial number: 47\n",
            "mean rewards for 100 consecutive trials: 33.47\n",
            "trial number: 48\n",
            "mean rewards for 100 consecutive trials: 26.92\n",
            "trial number: 49\n",
            "mean rewards for 100 consecutive trials: 155.58\n",
            "trial number: 50\n",
            "mean rewards for 100 consecutive trials: 29.06\n",
            "trial number: 51\n",
            "mean rewards for 100 consecutive trials: 40.48\n",
            "trial number: 52\n",
            "mean rewards for 100 consecutive trials: 49.73\n",
            "trial number: 53\n",
            "mean rewards for 100 consecutive trials: 43.32\n",
            "trial number: 54\n",
            "mean rewards for 100 consecutive trials: 49.96\n",
            "trial number: 55\n",
            "mean rewards for 100 consecutive trials: 49.3\n",
            "trial number: 56\n",
            "mean rewards for 100 consecutive trials: 63.97\n",
            "trial number: 57\n",
            "mean rewards for 100 consecutive trials: 43.13\n",
            "trial number: 58\n",
            "mean rewards for 100 consecutive trials: 55.35\n",
            "trial number: 59\n",
            "mean rewards for 100 consecutive trials: 46.09\n",
            "trial number: 60\n",
            "mean rewards for 100 consecutive trials: 53.67\n",
            "trial number: 61\n",
            "mean rewards for 100 consecutive trials: 71.79\n",
            "trial number: 62\n",
            "mean rewards for 100 consecutive trials: 49.16\n",
            "trial number: 63\n",
            "mean rewards for 100 consecutive trials: 123.88\n",
            "trial number: 64\n",
            "mean rewards for 100 consecutive trials: 91.49\n",
            "trial number: 65\n",
            "mean rewards for 100 consecutive trials: 71.54\n",
            "trial number: 66\n",
            "mean rewards for 100 consecutive trials: 98.86\n",
            "trial number: 67\n",
            "mean rewards for 100 consecutive trials: 179.95\n",
            "trial number: 68\n",
            "mean rewards for 100 consecutive trials: 148.55\n",
            "trial number: 69\n",
            "mean rewards for 100 consecutive trials: 146.84\n",
            "trial number: 70\n",
            "mean rewards for 100 consecutive trials: 164.04\n",
            "trial number: 71\n",
            "mean rewards for 100 consecutive trials: 140.79\n",
            "trial number: 72\n",
            "mean rewards for 100 consecutive trials: 146.47\n",
            "trial number: 73\n",
            "mean rewards for 100 consecutive trials: 142.32\n",
            "trial number: 74\n",
            "mean rewards for 100 consecutive trials: 162.36\n",
            "trial number: 75\n",
            "mean rewards for 100 consecutive trials: 154.0\n",
            "trial number: 76\n",
            "mean rewards for 100 consecutive trials: 157.64\n",
            "trial number: 77\n",
            "mean rewards for 100 consecutive trials: 196.5\n",
            "solved after 77 episods\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztZTW4_ALWpr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "7e1afee4-3802-4fcf-edbe-cc2d864db5e4"
      },
      "source": [
        "render_model()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}